clls() {
  KUBECONFIG_FILE="$HOME/.kube/config"
  TMP_FILE="/tmp/k8s-clusters-$(date +%s).tmp"
  
  # Backup existing kubeconfig
  if [ -f "$KUBECONFIG_FILE" ]; then
    cp "$KUBECONFIG_FILE" "${KUBECONFIG_FILE}.backup-$(date +%s)"
    # Keep only last 5 backups
    ls -t "${KUBECONFIG_FILE}.backup-"* 2>/dev/null | tail -n +6 | xargs -r rm
  fi
  
  # Get AWS account information
  account_id=$(aws sts get-caller-identity --query Account --output text)
  account_alias=$(aws iam list-account-aliases --query 'AccountAliases[0]' --output text 2>/dev/null)
  aws_profile=${AWS_PROFILE:-}
  
  # Determine prefix: alias > profile > account_id
  if [ -n "$account_alias" ] && [ "$account_alias" != "None" ]; then
    prefix="$account_alias"
  elif [ -n "$aws_profile" ]; then
    prefix="$aws_profile"
  else
    prefix="$account_id"
  fi
  
  echo "Using prefix: $prefix"
  echo "Discovering EKS clusters across all regions..."
  
  regions=($(aws account list-regions 2>/dev/null | jq -r '.Regions[].RegionName'))
  
  # If account list-regions fails, fall back to ec2 describe-regions
  if [ ${#regions[@]} -eq 0 ]; then
    regions=($(aws ec2 describe-regions --query 'Regions[].RegionName' --output text))
  fi
  
  N=20
  (
    for region in "${regions[@]}"; do
      ((i = i % N))
      ((i++ == 0)) && wait
      aws eks list-clusters --region "$region" 2>/dev/null | jq -r '.clusters[]' | sed -Ee "s/(.*)/$region|\1/g" >>$TMP_FILE &
    done
    wait
  )
  
  # Ensure kubeconfig exists
  if [ ! -f "$KUBECONFIG_FILE" ]; then
    echo "apiVersion: v1" > "$KUBECONFIG_FILE"
    echo "kind: Config" >> "$KUBECONFIG_FILE"
    echo "clusters: []" >> "$KUBECONFIG_FILE"
    echo "contexts: []" >> "$KUBECONFIG_FILE"
    echo "users: []" >> "$KUBECONFIG_FILE"
    echo "current-context: ''" >> "$KUBECONFIG_FILE"
  fi
  
  export KUBECONFIG="$KUBECONFIG_FILE"
  
  # Get existing contexts for this prefix before update
  existing_contexts=$(kubectl config get-contexts -o name 2>/dev/null | grep "^${prefix} | " || true)
  
  # Update/add kubeconfig for each discovered cluster
  cluster_count=0
  updated_count=0
  added_count=0
  
  while IFS='|' read -r region cluster; do
    if [ -n "$cluster" ]; then
      context_name="${prefix} | ${region} | ${cluster}"
      
      # Check if context already exists
      if echo "$existing_contexts" | grep -qF "${context_name}"; then
        echo "Refreshing cluster: $cluster (region: $region)"
        ((updated_count++))
      else
        echo "Adding new cluster: $cluster (region: $region)"
        ((added_count++))
      fi
      
      aws eks update-kubeconfig \
        --name "$cluster" \
        --region "$region" \
        --alias "$context_name" \
        --kubeconfig "$KUBECONFIG_FILE" 2>/dev/null
      
      if [ $? -eq 0 ]; then
        ((cluster_count++))
      else
        echo "  ⚠ Failed to update kubeconfig for $cluster in $region"
      fi
    fi
  done < "$TMP_FILE"
  
  chmod 600 "$KUBECONFIG_FILE"
  
  echo ""
  echo "✓ Successfully processed $cluster_count clusters for prefix: $prefix"
  echo "  - Added: $added_count new cluster(s)"
  echo "  - Refreshed: $updated_count existing cluster(s)"
  echo "✓ Kubeconfig saved to: $KUBECONFIG_FILE"
  echo ""
  echo "All contexts in kubeconfig:"
  kubectl config get-contexts -o name | sed 's/^/  - /'
  echo ""
  echo "Contexts with prefix '$prefix':"
  kubectl config get-contexts -o name | grep "^${prefix} | " | sed 's/^/  - /' || echo "  (none)"
  echo ""
  echo "Use 'kubectx' to switch between contexts"
  
  [[ ! -e $TMP_FILE ]] || rm $TMP_FILE
}

cladd() {
  if [ -z "$1" ]; then
    echo "Usage: cladd <kubeconfig-file>"
    echo "Example: cladd test-kubeconfig"
    return 1
  fi
  
  SOURCE_KUBECONFIG="$1"
  TARGET_KUBECONFIG="$HOME/.kube/config"
  
  # Check if source kubeconfig exists
  if [ ! -f "$SOURCE_KUBECONFIG" ]; then
    echo "Error: Kubeconfig file '$SOURCE_KUBECONFIG' not found"
    return 1
  fi
  
  # Validate source kubeconfig is valid YAML
  if ! kubectl --kubeconfig="$SOURCE_KUBECONFIG" config view &>/dev/null; then
    echo "Error: '$SOURCE_KUBECONFIG' is not a valid kubeconfig file"
    return 1
  fi
  
  # Backup existing kubeconfig
  if [ -f "$TARGET_KUBECONFIG" ]; then
    cp "$TARGET_KUBECONFIG" "${TARGET_KUBECONFIG}.backup-$(date +%s)"
    # Keep only last 5 backups
    ls -t "${TARGET_KUBECONFIG}.backup-"* 2>/dev/null | tail -n +6 | xargs -r rm
    echo "✓ Backed up existing kubeconfig"
  fi
  
  # Create target kubeconfig if it doesn't exist
  if [ ! -f "$TARGET_KUBECONFIG" ]; then
    mkdir -p "$(dirname "$TARGET_KUBECONFIG")"
    echo "apiVersion: v1" > "$TARGET_KUBECONFIG"
    echo "kind: Config" >> "$TARGET_KUBECONFIG"
    echo "clusters: []" >> "$TARGET_KUBECONFIG"
    echo "contexts: []" >> "$TARGET_KUBECONFIG"
    echo "users: []" >> "$TARGET_KUBECONFIG"
    echo "current-context: ''" >> "$TARGET_KUBECONFIG"
    echo "✓ Created new kubeconfig at $TARGET_KUBECONFIG"
  fi
  
  # Get contexts from source kubeconfig
  source_contexts=$(kubectl --kubeconfig="$SOURCE_KUBECONFIG" config get-contexts -o name 2>/dev/null)
  
  if [ -z "$source_contexts" ]; then
    echo "Warning: No contexts found in '$SOURCE_KUBECONFIG'"
    return 1
  fi
  
  echo "Found contexts in source kubeconfig:"
  echo "$source_contexts" | sed 's/^/  - /'
  echo ""
  
  # Merge kubeconfigs
  echo "Merging kubeconfig files..."
  KUBECONFIG="$TARGET_KUBECONFIG:$SOURCE_KUBECONFIG" kubectl config view --flatten > "${TARGET_KUBECONFIG}.tmp"
  
  if [ $? -eq 0 ]; then
    mv "${TARGET_KUBECONFIG}.tmp" "$TARGET_KUBECONFIG"
    chmod 600 "$TARGET_KUBECONFIG"
    echo "✓ Successfully merged kubeconfig"
  else
    rm -f "${TARGET_KUBECONFIG}.tmp"
    echo "Error: Failed to merge kubeconfig files"
    return 1
  fi
  
  # Show summary
  echo ""
  echo "All contexts now in $TARGET_KUBECONFIG:"
  kubectl config get-contexts -o name | sed 's/^/  - /'
  echo ""
  echo "Use 'kubectx' to switch between contexts"
}

kdebug() {
  kubectl debug node/$1 -it --image=ubuntu
}

_lima() {
  port=$(limactl list --json | jq .sshLocalPort)
  if [ -n $port ]; then
    ssh lima@127.0.0.1 -p $port
  else
    echo "VM not started"
  fi
}

rebase() {
  if [ ! -z $1 ]; then
    branch=$1
  else
    branch="master"
  fi
  git fetch --all
  git rebase origin/$branch
  git push -f
}

generate_aws_exports() {
  if [ -z "$1" ]; then
    PROFILE="default"
  else
    PROFILE=$1
  fi

  awk -v profile="$PROFILE" '
  /^\[/{f=0} 
  /^\[/{if ($1 == "[" profile "]") f=1} 
  f && /aws_access_key_id/{print "export AWS_ACCESS_KEY_ID=" $3} 
  f && /aws_secret_access_key/{print "export AWS_SECRET_ACCESS_KEY=" $3}
  f && /aws_session_token/{print "export AWS_SESSION_TOKEN=" $3}
  ' ~/.aws/credentials
}

get_aws_federated_url() {
  # Ensure required environment variables are set
  if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_SESSION_TOKEN" ]; then
    echo "Please set AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN environment variables."
    return 1
  fi

  # Create JSON session data
  session_data=$(jq -n --arg sessionId "$AWS_ACCESS_KEY_ID" --arg sessionKey "$AWS_SECRET_ACCESS_KEY" --arg sessionToken "$AWS_SESSION_TOKEN" \
    '{sessionId: $sessionId, sessionKey: $sessionKey, sessionToken: $sessionToken}')

  # Define AWS federated sign-in endpoint
  aws_federated_signin_endpoint="https://signin.aws.amazon.com/federation"

  # Get the sign-in token
  response=$(curl -s -G "$aws_federated_signin_endpoint" --data-urlencode "Action=getSigninToken" --data-urlencode "SessionDuration=43200" --data-urlencode "Session=$session_data")
  signin_token=$(echo "$response" | jq -r '.SigninToken')

  if [ -z "$signin_token" ]; then
    echo "Failed to get a sign-in token from the AWS sign-in federation endpoint."
    return 1
  fi

  echo "Got a sign-in token from the AWS sign-in federation endpoint."

  # Create the federated URL
  query_string=$(jq -rn --arg Action "login" --arg Issuer "" --arg Destination "https://console.aws.amazon.com/" --arg SigninToken "$signin_token" \
    '{Action: $Action, Issuer: $Issuer, Destination: $Destination, SigninToken: $SigninToken} | to_entries | map("\(.key)=\(.value|@uri)") | join("&")')

  federated_url="$aws_federated_signin_endpoint?$query_string"

  # Output the URL as a clickable hyperlink
  echo -e "${federated_url}"
}

sap() {
  choice=$(awk -F' *= *' '/^aws_profile/{p=$2} /^region/{print p " - " $2}' ~/.saml2aws | fzf --prompt "Choose SAML2AWS profile:")
  saml2aws login -a "$(echo $choice | awk '{print $1}')"

  if [ $? -ne 0 ]; then
    echo "Failed to authenticate SAML2AWS"
    return 1
  fi

  export AWS_PROFILE=$(echo $choice | awk '{print $1}')
  export AWS_REGION=$(echo $choice | awk '{print $3}')

  echo "Successfully set SAML2AWS profile $AWS_PROFILE in $AWS_REGION"
}